---
title: I've reviewed hundreds of applicant-tracking systems. Here's why your
  résumé may never reach a hiring manager.
date: 2025-09-11T16:26:00.000-04:00
description: >-
  Applicant-tracking systems can be biased, said Rod Samra, a former Labor
  Department investigator.

  These systems can amplify biases if algorithms are poorly designed or lack oversight, he said.

  Samra advises job seekers to mirror job descriptions and know their rights.
linkedin_url: https://www.newsbreak.com/business-insider-562169/4227101771014-i-ve-reviewed-hundreds-of-applicant-tracking-systems-here-s-why-your-r-sum-may-never-reach-a-hiring-manager
thumbnail: /images/blog/screenshot_15-11-2025_163014_www.newsbreak.com.jpeg
---
Many employers use AI-powered applicant-tracking systems to sort through résumés and identify job candidates. I've audited hundreds of these systems over the course of my career. There is often no human intervention, and that's a problem.

AI is a double-edged sword. It can reduce biases by standardizing the résumé-review process, but it can also amplify biases if algorithms are poorly designed or tested. Someone needs to step in and look at the data to make sure protected groups aren't experiencing an adverse impact. But that doesn't always happen.

These biases are often subtle. For instance, they may favor male over female applicants. Even when résumés don't state gender directly, the system can infer it from details such as membership in a fraternity or sorority.

The high-profile, ongoing legal case Mobley v. Workday alleges this kind of bias.

**Overly specific language and filtering**
Another problem is that applicant-tracking systems tend to look for language that's overly specific. A job ad may say "leadership skills" are required, and the system may be set up to find those exact words only, excluding candidates whose résumés instead say things like, "I've led teams" or "I've held many leadership positions." If you don't have the right terminology, the system can weed you out.

Exclusionary filters, which reject applicants based on information such as ZIP codes and graduation years, can disproportionately impact certain groups. Other filters penalize applicants for having nontraditional career paths and credentials.

Employers aren't necessarily aware that this is happening due to the lack of human intervention. It's like having a security camera that records what's going on, but nobody's looking at the footage.

**A quick rejection**
Many job seekers also don't realize they're getting rejected by machines. But there are some signs you can look out for that signal a tracking system is biased or has rigid keyword-matching.

One is that you receive an automated rejection within minutes or hours of applying, even when your qualifications clearly match the job description. Another is when you're told your résumé "couldn't be parsed" or "didn't meet minimum criteria" without an explanation.

Screening questions can also serve as proxies for protected traits when they're about unnecessary personal details, such as an applicant's exact birth date or graduation year. This allows bias to creep in under the guise of "fit" or "eligibility."

**Vague feedback**
The same goes for video- or game-based assessments with no transparency. You're asked to complete AI-scored tests, but the employer won't explain what's being measured or how scores are calculated. Research shows these tactics can lead to bias through facial recognition, speech analysis, or cultural references, which can be disadvantageous to candidates with disabilities, neurodivergence, or nonnative accents.

A lack of feedback can also be an indicator of automation bias. When you ask why you were rejected, you get vague or generic responses like "you were not the right fit," with no specifics. Ethical AI hiring practices require at least some transparency about evaluation criteria.

**Getting your résumé past ATS**
To increase the odds of getting your résumé past an applicant-tracking system and into a hiring manager's hands, mirror the job description. Use the employer's exact words and phrasing.

Meanwhile, know your rights and keep records of your applications, rejections, and any demographic patterns you notice. If you believe you've been discriminated against, you can file a complaint with the EEOC or a state that requires employers to disclose the use of AI-based hiring tools, such as Illinois and New York.
